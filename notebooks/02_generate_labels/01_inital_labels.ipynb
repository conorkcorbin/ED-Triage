{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019 Labels\n",
    "\n",
    "This notebook generates labels for the 2019 data.\n",
    "\n",
    "We will generate the following labels:\n",
    "1. `admit_label`: level of care at time of admit\n",
    "2. `24hr_label`: most recent level of care prior to 24 hrs after admit\n",
    "3. `12hr_label`: most recent level of care prior to 12 hrs after admit\n",
    "4. `acute_to_icu_label`: label switched from acute to ICU from admit to 24 hr time\n",
    "4. `icu_to_acute_label`: label switched from ICU to acute from admit to 24 hr time\n",
    "\n",
    "\n",
    "Labels 1 through 3 reflect the following:\n",
    "- 1 = critical care\n",
    "- 0 = not critical care \n",
    "\n",
    "Labels 4 through 5 reflect:\n",
    "- 1 = switched care level\n",
    "- 0 = did not switch care level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os.path\n",
    "from os import path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download latest cohort data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The data was downloaded from the BQ from the `Traige_TE.triage_cohort_final` table. This table contains the newest cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forrepo = 1 # change this to 0 if you want to see hidden columns displayed\n",
    "\n",
    "hidecols = []\n",
    "if forrepo:\n",
    "    hidecols=['anon_id', 'pat_enc_csn_id_coded', 'inpatient_data_id_coded'] # these are hidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folder with downloaded data\n",
    "datadir = \"../../../../2019_data\"\n",
    "\n",
    "cohort = pd.read_csv(\"{}/triage_cohort_final.csv\".format(datadir))\n",
    "\n",
    "cohort.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "print(cohort.shape)\n",
    "cohort.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `admit_time` column contains the adjusted/earliest time between `admit_time_jittered` from the `ADT` table and the admission ordered time form the `order_proc` table. This is the time that we will use for the admission time.\n",
    "\n",
    "We are not going to use this admit time. Instead, we use the earliest admit time based on the `effective_time_jittered_utc` column in the `ADT` table. We'll grab the admit time from Conor's cohort for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conors_cohort = pd.read_csv(\"{}/triage_cohort_draft_2019.csv\".format(datadir))\n",
    "conors_cohort.head()\n",
    "\n",
    "# join this to the cohort table\n",
    "cohort_joined = cohort.merge(conors_cohort[['pat_enc_csn_id_coded', 'admit_time_jittered']], how='left')\n",
    "cohort_joined.head()\n",
    "\n",
    "cohort_joined[cohort_joined.admit_time == cohort_joined.admit_time_jittered].drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the admit time was already updated in this table. We can just use the original time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the ADT table for this cohort\n",
    "\n",
    "We need to pull the `ADT` data for this new cohort. I already ran a SQL call directly on BQ to form the cohort and stored the table under `traige_TE.triage_cohort_adt_2019`\n",
    "\n",
    "Here's the SQL code used:\n",
    "\n",
    "`select shc.anon_id, shc.pat_enc_csn_id_coded, pat_class, pat_lv_of_care, event_type, pat_service, status_of_bed, accomodation\n",
    "  from shc_core.adt shc\n",
    "  right join conor_db.triage_cohort_draft_2019 c \n",
    "  on shc.anon_id = c.anon_id and shc.pat_enc_csn_id_coded = c.pat_enc_csn_id_coded`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to BQ - uncomment all of this if the data is not on computer\n",
    "# cohort_adt_file = \"../2019_data/triage_cohort_adt_2019.csv\"\n",
    "\n",
    "# %load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bigquery adt\n",
    "# select *\n",
    "# from traige_TE.triage_cohort_2019_adt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data\n",
    "# adt.to_csv(cohort_adt_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ADT table\n",
    "\n",
    "Start here if the data has already been pulled from BQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to describe the tables\n",
    "def describe_df(df):\n",
    "    print(\"df shape\", df.shape)\n",
    "    print(\"unique CSNs: \", df.pat_enc_csn_id_coded.nunique())\n",
    "    print(\"unique patients: \", df.anon_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = pd.read_csv(\"{}/triage_cohort_adt_2019.csv\".format(datadir))\n",
    "\n",
    "describe_df(adt)\n",
    "\n",
    "adt.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the adt to the cohort to make sure we have the correct cohort\n",
    "joined_cohort_adt = cohort.merge(adt, on=['anon_id', 'pat_enc_csn_id_coded'],\n",
    "                       how='left')\n",
    "\n",
    "describe_df(joined_cohort_adt)\n",
    "\n",
    "joined_cohort_adt.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cohort: \", cohort.shape, \"adt: \", adt.shape, \"joined_demo_adt: \", joined_cohort_adt.shape)\n",
    "\n",
    "print(\"\\nNumber of unique CSNs:\")\n",
    "print(\"cohort:\", cohort.pat_enc_csn_id_coded.nunique(),\n",
    "     \"adt:\", adt.pat_enc_csn_id_coded.nunique(),\n",
    "     \"joined:\", joined_cohort_adt.pat_enc_csn_id_coded.nunique())\n",
    "\n",
    "print(\"\\nNumber of unique anon_ids:\")\n",
    "print(\"cohort:\", cohort.anon_id.nunique(),\n",
    "     \"adt:\", adt.anon_id.nunique(),\n",
    "     \"joined:\", joined_cohort_adt.anon_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare table for making labels\n",
    "\n",
    "We need to change the times into datetime format so we can work with them to create the labels. Also, create a column that tells us how long it's been since admit time for each event in the `ADT` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the admit time to datetime\n",
    "joined_cohort_adt.admit_time = pd.to_datetime(joined_cohort_adt.admit_time)\n",
    "\n",
    "# change the effective time to datetime\n",
    "joined_cohort_adt['effective_time_jittered_utc'] = pd.to_datetime(joined_cohort_adt.effective_time_jittered_utc)\n",
    "\n",
    "# change the event time to datetime\n",
    "joined_cohort_adt['event_time_jittered_utc'] = pd.to_datetime(joined_cohort_adt.event_time_jittered_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute time since event - this step take a little while\n",
    "joined_cohort_adt['effective_time_since_admit'] = joined_cohort_adt.apply(lambda x: x.effective_time_jittered_utc - x.admit_time, axis=1)\n",
    "joined_cohort_adt['event_time_since_admit'] = joined_cohort_adt.apply(lambda x: x.event_time_jittered_utc - x.admit_time, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the CSN from last time that was messed up. This CSN had two patients last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_cohort_adt[joined_cohort_adt.pat_enc_csn_id_coded == 131227093710].drop(hidecols, axis=1, errors='ignore') # looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_used = \"effective\" # change this to look at the different times (either effective or event)\n",
    "# time_used = \"event\"\n",
    "\n",
    "key = \"{}_time_since_admit\".format(time_used)\n",
    "\n",
    "# check out time since admit\n",
    "print(joined_cohort_adt[key].describe())\n",
    "\n",
    "# look at all of the ADT events for these CSNs that occur prior to admission\n",
    "prior_to_admit = joined_cohort_adt[joined_cohort_adt[key] < timedelta(hours=0)]\n",
    "\n",
    "# number of ADT events that occur before admission\n",
    "print(prior_to_admit.shape)\n",
    "\n",
    "# this tells us where people were before admission\n",
    "print(prior_to_admit.pat_class.value_counts())\n",
    "\n",
    "prior_to_admit.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some patients have many CSNs in the cohort\n",
    "\n",
    "Most patients only have one CSN in the `demo` table, but there are some with many CSNs. The max number of CSNs for one individual is 37. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = joined_cohort_adt.groupby('anon_id')['pat_enc_csn_id_coded'].nunique().sort_values(ascending=False)\n",
    "\n",
    "# distribution of CSNs per patient\n",
    "print(counts.describe())\n",
    "\n",
    "# number of patients with more than one CSN\n",
    "print(\"\\nPatients with multiple CSNs: \", sum(counts > 1))\n",
    "\n",
    "counts.head(20)\n",
    "# joined_cohort_adt[filtered_demo.anon_id == 'JCe8f38d'].sort_values('admit_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into event time and effective time differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get difference between events\n",
    "joined_cohort_adt['effective_minus_event_time'] = (joined_cohort_adt.effective_time_jittered_utc \n",
    "                                                   - joined_cohort_adt.event_time_jittered_utc)\n",
    "\n",
    "joined_cohort_adt.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Label: Level of Care at Admit\n",
    "\n",
    "We need to get the first admission event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patients missing lv of care \n",
    "\n",
    "There are some patients that are missing the `pat_lv_of_care` entry for the admit event. I looked through a handfull manually and it looks like these individuals tend to be missing the `pat_lv_of_care` for all of their ADT events. This means we can't assign them any labels and so should be removed from the dataset.\n",
    "\n",
    "There are **1007** cases that have no admit lv of care. See the next two boxes below for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try filtering for exact admit events\n",
    "admit_events = joined_cohort_adt[joined_cohort_adt.admit_time == joined_cohort_adt.effective_time_jittered_utc] \n",
    "# admit_events = admit_events[admit_events.pat_class == \"Inpatient\"]\n",
    "\n",
    "print(\"joined_cohort_adt\")\n",
    "describe_df(joined_cohort_adt)\n",
    "print(\"\\nadmit events\")\n",
    "describe_df(admit_events) # we don't lose any CSNs so that's good\n",
    "\n",
    "\n",
    "\n",
    "# there are multiple admit events for some CSNs - check that the lv of care are the same\n",
    "care_counts = admit_events.groupby(['pat_enc_csn_id_coded']).pat_lv_of_care.nunique()\n",
    "print(\"\\n\",care_counts.describe())\n",
    "# looks like some CSNs are missing an admit event label, \n",
    "# some have multiple level of care labels --> need to pull sequence numbers for events\n",
    "\n",
    "missing_admits = care_counts[care_counts != 1].reset_index()\n",
    "\n",
    "missing_admits.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['pat_class', 'pat_lv_of_care', \n",
    "        'admit_time', 'effective_time_jittered_utc', 'event_time_jittered_utc', 'effective_time_since_admit',\n",
    "       'event_time_since_admit', 'effective_minus_event_time', \n",
    "       'event_type', 'anon_id', 'pat_enc_csn_id_coded']\n",
    "\n",
    "# check on these missing admit CSNs\n",
    "i = 6\n",
    "missing_csns = missing_admits[missing_admits.pat_lv_of_care == 0]\n",
    "\n",
    "\n",
    "missing_csns = missing_csns.pat_enc_csn_id_coded.values\n",
    "print(len(missing_csns))\n",
    "missing_csn = missing_csns[i]\n",
    "check = joined_cohort_adt[joined_cohort_adt.pat_enc_csn_id_coded == missing_csn]\n",
    "check[cols].sort_values(by=['anon_id', 'pat_enc_csn_id_coded', 'effective_time_jittered_utc']).drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out when these missing admit individuals get their first label\n",
    "len(missing_csns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the final labels that we used\n",
    "final_labels = pd.read_csv(\"{}/triage_to_keep_cohort_with_labels_updated.csv\".format(datadir))\n",
    "\n",
    "final_labels.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels_sub = final_labels[final_labels.pat_enc_csn_id_coded.isin(cohort.pat_enc_csn_id_coded)]\n",
    "\n",
    "final_labels_sub.has_admit_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_labels = final_labels_sub[(~final_labels_sub.pat_enc_csn_id_coded.isin(missing_csns)) &\n",
    "                               (final_labels_sub.has_admit_label == 0)]\n",
    "extra_labels.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check out these extra labels that are in the final labels but not found as missing admit labels here\n",
    "# this might be an error - there are only 9 though so it's not a huge dealb\n",
    "i = 0\n",
    "extra_csns = extra_labels.pat_enc_csn_id_coded.values\n",
    "csn = extra_csns[i]\n",
    "\n",
    "print(len(extra_csns))\n",
    "\n",
    "joined_cohort_adt[joined_cohort_adt.pat_enc_csn_id_coded == csn].drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find patients with NaN only for lv of care\n",
    "missing_adt = joined_cohort_adt[joined_cohort_adt.pat_enc_csn_id_coded.isin(missing_csns)]\n",
    "\n",
    "not_all_nan = missing_adt[~missing_adt.pat_lv_of_care.isnull()]\n",
    "\n",
    "not_all_nan_csns = not_all_nan.pat_enc_csn_id_coded.unique()\n",
    "\n",
    "fully_missing_csns = [x for x in missing_csns if not x in not_all_nan_csns]\n",
    "\n",
    "missing_csns_adt = cohort[cohort.pat_enc_csn_id_coded.isin(fully_missing_csns)]\n",
    "\n",
    "print(len(fully_missing_csns))\n",
    "\n",
    "# missing_csns_adt.to_csv(\"../2019_data/cohort_2019_missing_pat_lv_of_care.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove patients with no labels in any events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cohort_adt = joined_cohort_adt[~joined_cohort_adt.pat_enc_csn_id_coded.isin(fully_missing_csns)]\n",
    "\n",
    "print(\"joined_cohort_adt\")\n",
    "describe_df(joined_cohort_adt)\n",
    "print(\"\\nfiltered_cohort_adt\")\n",
    "describe_df(filtered_cohort_adt) # removed 202 patients\n",
    "\n",
    "filtered_cohort = cohort[~cohort.pat_enc_csn_id_coded.isin(fully_missing_csns)]\n",
    "print(\"\\n\\njoined_cohort_adt\")\n",
    "describe_df(joined_cohort_adt)\n",
    "print(\"\\nfiltered_cohort\")\n",
    "describe_df(filtered_cohort) # removed 202 patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue with patients that have admit events with lv of care "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only patients with one lv of care label at admit time\n",
    "counts = care_counts.reset_index()\n",
    "keep_csns = counts[counts.pat_lv_of_care == 1].pat_enc_csn_id_coded.values\n",
    "\n",
    "keep_admits = admit_events[admit_events.pat_enc_csn_id_coded.isin(keep_csns)]\n",
    "\n",
    "print(\"filtered_cohort_adt\")\n",
    "describe_df(filtered_cohort_adt)\n",
    "print(\"\\nkeep admits\")\n",
    "describe_df(keep_admits) # there are multiple inpatient admit events, but they have the same label so it's okay\n",
    "\n",
    "print(\"\\nkeep admits + removed csns =\", \n",
    "      keep_admits.pat_enc_csn_id_coded.nunique() + len(missing_csns)) # we're only missing the ones with no labels\n",
    "\n",
    "print(\"\\nmissing csns: \", len(missing_csns))\n",
    "\n",
    "# keep only the first admit event for each csn\n",
    "# all admit events have same label so it's okay to keep\n",
    "unique_admits = keep_admits.groupby(\"pat_enc_csn_id_coded\").first().reset_index()\n",
    "\n",
    "admit_labels = unique_admits[['pat_enc_csn_id_coded', 'pat_lv_of_care']]\n",
    "print(admit_labels.pat_lv_of_care.value_counts()) # these NeoNatal ICU and Newborn Nursery might be weird to keep ***\n",
    "\n",
    "admit_labels['admit_label'] = (admit_labels.pat_lv_of_care == \"Critical Care\").astype(int)\n",
    "\n",
    "print(admit_labels.admit_label.value_counts())\n",
    "\n",
    "admit_labels.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csn = admit_labels[admit_labels.pat_lv_of_care == 'Newborn Nursery - VC Only'].pat_enc_csn_id_coded.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check = filtered_cohort_adt[filtered_cohort_adt.pat_enc_csn_id_coded == csn]\n",
    "check[cols].sort_values('event_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cohort_labels = filtered_cohort.merge(admit_labels[['pat_enc_csn_id_coded', 'admit_label']], how='left')\n",
    "\n",
    "# some are mising an admit label because they were NaN at admit time\n",
    "sum(filtered_cohort_labels.admit_label.isnull())\n",
    "\n",
    "filtered_cohort_labels.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Recent Care Labels\n",
    "\n",
    "Now we'll get the labels for the most recent event prior to X hours, for X=12 and 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 24\n",
    "\n",
    "def get_adtX(X):\n",
    "    # take only events that occur after admit but before the X hours mark\n",
    "    adt_X = filtered_cohort_adt[(filtered_cohort_adt.effective_time_since_admit >= timedelta(hours=0))\n",
    "                                 &\n",
    "                                 (filtered_cohort_adt.effective_time_since_admit <= timedelta(hours=X))\n",
    "                                &\n",
    "                                (~filtered_cohort_adt.pat_lv_of_care.isnull())\n",
    "                                ]\n",
    "\n",
    "    # check out distribution of times\n",
    "    print(adt_X.effective_time_since_admit.describe(), \"\\n\")\n",
    "    \n",
    "    print(\"filtered_cohort_adt\")\n",
    "    describe_df(filtered_cohort_adt)\n",
    "    print(\"\\nadt_X\")\n",
    "    # check if we lost anyone - we're missing some\n",
    "    describe_df(adt_X)\n",
    "\n",
    "\n",
    "    print(\"\\nmissing number of csns:\")\n",
    "    filtered_cohort_csns = filtered_cohort_adt.pat_enc_csn_id_coded.unique()\n",
    "    adt_X_csns = adt_X.pat_enc_csn_id_coded.unique()\n",
    "    print(len(filtered_cohort_csns) - len(adt_X_csns))\n",
    "    \n",
    "    # get these missing csns to manual check\n",
    "    missing_csns = [x for x in filtered_cohort_csns if x not in adt_X_csns]\n",
    "    \n",
    "    return (adt_X, missing_csns)\n",
    "\n",
    "\n",
    "adt_X, missing_csns = get_adtX(X=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing 24 hour labels\n",
    "\n",
    "There are 84 individuals missing 24 hr labels. I checked the first three and they seem to be those with NaN values for `pat_lv_of_care` for all events that occur within 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "missing_csn = missing_csns[i]\n",
    "check = filtered_cohort_adt[filtered_cohort_adt.pat_enc_csn_id_coded == missing_csn]\n",
    "check[cols].sort_values('effective_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_events():\n",
    "    # sort by the effective time of events\n",
    "    adt_X.sort_values(by=['anon_id', 'pat_enc_csn_id_coded','effective_time_since_admit', 'seq_num_in_enc', 'seq_num_in_bed_min'], inplace=True)\n",
    "\n",
    "    describe_df(adt_X)\n",
    "\n",
    "    # group by CSN and get first event \n",
    "    recent_events = adt_X.groupby('pat_enc_csn_id_coded').last().reset_index()\n",
    "\n",
    "    print(recent_events.effective_time_since_admit.describe())\n",
    "\n",
    "    return recent_events\n",
    "\n",
    "recent_events = get_recent_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some patients' most recent event is very early\n",
    "\n",
    "Minimum is 1 minute after admit. Check this guy out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_events.sort_values(by=['effective_time_since_admit']).head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this checks out, so at least nothing wrong with code\n",
    "check = filtered_cohort_adt[filtered_cohort_adt.pat_enc_csn_id_coded == 131087352675]\n",
    "check[cols].sort_values('effective_time_since_admit').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have one row for each event now - each row is the last entry for each event prior to 24 hr mark\n",
    "print(recent_events.pat_enc_csn_id_coded.nunique())\n",
    "print(recent_events.shape)\n",
    "\n",
    "describe_df(recent_events)\n",
    "\n",
    "recent_events.effective_time_since_admit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue with labels again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the level of care assignments across all individuals\n",
    "print(recent_events.pat_lv_of_care.value_counts())\n",
    "\n",
    "sum(recent_events.pat_lv_of_care.isnull()) # these are NaN lv of care prior to 24 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"label_{}hr_recent\".format(X)\n",
    "recent_events[label_name] = (recent_events.pat_lv_of_care == 'Critical Care').astype(int)\n",
    "recent_events.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab relevant columns\n",
    "labels = recent_events[['pat_enc_csn_id_coded', label_name]]\n",
    "\n",
    "# join to demo table\n",
    "filtered_cohort_labels2 = filtered_cohort_labels.merge(labels, how='left', on='pat_enc_csn_id_coded')\n",
    "filtered_cohort_labels2[label_name] = filtered_cohort_labels2[label_name]\n",
    "\n",
    "filtered_cohort_labels2.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make 12 hour most recent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=12\n",
    "adt_X, missing_csns = get_adtX(X=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing 12 hr labels\n",
    "\n",
    "There are 136 CSNs missing 12 hour labels. We can check out a couple of them. Looks legit. This should be a superset of the missing 24 hour label CSNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "missing_csn = missing_csns[i]\n",
    "check = filtered_cohort_adt[filtered_cohort_adt.pat_enc_csn_id_coded == missing_csn]\n",
    "check[cols].sort_values('effective_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last event within 12 hours for each CSN\n",
    "recent_events = get_recent_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the level of care assignments across all individuals\n",
    "print(recent_events.pat_lv_of_care.value_counts())\n",
    "\n",
    "sum(recent_events.pat_lv_of_care.isnull()) # these are NaN lv of care prior to 24 hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"label_{}hr_recent\".format(X)\n",
    "recent_events[label_name] = (recent_events.pat_lv_of_care == 'Critical Care').astype(int)\n",
    "\n",
    "print(recent_events[label_name].value_counts())\n",
    "recent_events.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab relevant columns\n",
    "labels = recent_events[['pat_enc_csn_id_coded', label_name]]\n",
    "\n",
    "# join to demo table\n",
    "filtered_cohort_labels3 = filtered_cohort_labels2.merge(labels, how='left', on='pat_enc_csn_id_coded')\n",
    "filtered_cohort_labels3[label_name] = filtered_cohort_labels3[label_name]\n",
    "\n",
    "filtered_cohort_labels3.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cohort_labels3.admit_label = filtered_cohort_labels3.admit_label.astype(\"Int64\")\n",
    "filtered_cohort_labels3['label_24hr_recent'] = filtered_cohort_labels3['label_24hr_recent'].astype(\"Int64\")\n",
    "filtered_cohort_labels3['label_12hr_recent'] = filtered_cohort_labels3['label_12hr_recent'].astype(\"Int64\")\n",
    "\n",
    "filtered_cohort_labels3.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the missing label count for all three labels\n",
    "print(sum(filtered_cohort_labels3.admit_label.isnull()))\n",
    "\n",
    "print(sum(filtered_cohort_labels3['label_24hr_recent'].isnull()))\n",
    "\n",
    "print(sum(filtered_cohort_labels3['label_12hr_recent'].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_cohort_labels3['admit_label'].value_counts(), \"\\n\")\n",
    "print(filtered_cohort_labels3['label_24hr_recent'].value_counts(), \"\\n\")\n",
    "print(filtered_cohort_labels3['label_12hr_recent'].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these to file to upload to BQ\n",
    "# filtered_cohort_labels3.to_csv(\"../2019_data/triage_cohort_final_with_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(filtered_cohort_labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Switch Labels\n",
    "\n",
    "We're creating labels that indicate whether a CSN switched from acute -> ICU or vice versa between admit time and 24 hours. For CSNs with both labels, this will be easy. \n",
    "\n",
    "However, some CSNs do not have admit labels, but they do have 24 hour labels. We will \n",
    "1. give these people a label based on their earliest level of care and their 24 hour label. \n",
    "2. We'll include a flag to indicate that these people didn't have admit labels. \n",
    "3. We'll also include the time of their earliest label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get flag to indicate whether individuals had an admit label\n",
    "switch_labels = filtered_cohort_labels3\n",
    "switch_labels['has_admit_label'] = (~switch_labels.admit_label.isnull()).astype(int)\n",
    "print(switch_labels.has_admit_label.value_counts())\n",
    "\n",
    "switch_labels.head()\n",
    "\n",
    "# subset to those that do not have admit label\n",
    "no_admit = switch_labels[switch_labels.has_admit_label == 0]\n",
    "no_admit.head()\n",
    "no_admit_csns = no_admit.pat_enc_csn_id_coded.values\n",
    "\n",
    "print(\"new cohort:\")\n",
    "print(describe_df(filtered_cohort_labels3))\n",
    "print(\"\\nno admit\")\n",
    "print(describe_df(no_admit)) # 796 CSNs with no admit time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing all labels\n",
    "\n",
    "There are some people who are missing labels for admit time, 12 hr, and 24 hr. We can't really do anything with these right now. We'll identify these individuals and remove them from the cohort.\n",
    "\n",
    "We can also look at the distribution of their first labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find csns with no labels across the board\n",
    "missing_labels = filtered_cohort_labels3[['admit_label', \n",
    "                        'label_12hr_recent', 'label_24hr_recent']].isnull().astype(int)\n",
    "missing_labels['pat_enc_csn_id_coded'] = filtered_cohort_labels3['pat_enc_csn_id_coded']\n",
    "\n",
    "no_admit = missing_labels[missing_labels.admit_label == 1] \n",
    "no_labels = no_admit[no_admit.label_24hr_recent == 1]\n",
    "\n",
    "print(no_labels['admit_label'].value_counts()) # 82 people have no labels before 24 hrs\n",
    "\n",
    "# manuall check some of them - looks good\n",
    "# new_cohort[new_cohort.pat_enc_csn_id_coded == no_labels.pat_enc_csn_id_coded.values[50]]\n",
    "\n",
    "no_labels_csns = no_labels.pat_enc_csn_id_coded.values # will probably remove these from cohort\n",
    "\n",
    "# pull the adt for these CSNs with no admit times\n",
    "no_labels_adt = filtered_cohort_adt[filtered_cohort_adt.pat_enc_csn_id_coded.isin(no_labels_csns)]\n",
    "\n",
    "## these individuals must have a label somewhere, find out where\n",
    "\n",
    "# sort out events with no lv of care\n",
    "has_lv_of_care = no_labels_adt[~no_labels_adt.pat_lv_of_care.isnull()]\n",
    "has_lv_of_care = has_lv_of_care[has_lv_of_care.effective_time_since_admit > timedelta(hours=0)]\n",
    "has_lv_of_care.pat_enc_csn_id_coded.nunique() # we have at least one per csn \n",
    "\n",
    "# find first event for each csn\n",
    "has_lv_of_care.sort_values(by=['pat_enc_csn_id_coded', 'event_time_jittered_utc'], inplace=True)\n",
    "first_label = has_lv_of_care.groupby(['pat_enc_csn_id_coded']).first()\n",
    "\n",
    "sec_since_admit = first_label.effective_time_since_admit.astype('timedelta64[s]')\n",
    "hour_since_admit = sec_since_admit / 3600 # num of sec in an hour\n",
    "print(hour_since_admit.describe())\n",
    "hour_since_admit.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue without these individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the no_admit cohort but not the no_label cohort\n",
    "has_some_label = filtered_cohort_labels3[~filtered_cohort_labels3.pat_enc_csn_id_coded.isin(no_labels_csns)] # 714 are left\n",
    "switch_cohort = has_some_label[has_some_label.pat_enc_csn_id_coded.isin(no_admit_csns)]\n",
    "\n",
    "## find the earliest level of care \n",
    "switch_cohort_csns = switch_cohort.pat_enc_csn_id_coded.values\n",
    "\n",
    "# pull the adt for these CSNs with no admit times\n",
    "switch_cohort_adt = filtered_cohort_adt[\n",
    "    filtered_cohort_adt.pat_enc_csn_id_coded.isin(switch_cohort_csns)]\n",
    "\n",
    "## these individuals must have a label somewhere, find out where\n",
    "\n",
    "# sort out events with no lv of care\n",
    "has_lv_of_care = switch_cohort_adt[~switch_cohort_adt.pat_lv_of_care.isnull()]\n",
    "print(has_lv_of_care.pat_enc_csn_id_coded.nunique())\n",
    "has_lv_of_care = has_lv_of_care[has_lv_of_care.effective_time_since_admit > timedelta(hours=0)]\n",
    "print(has_lv_of_care.pat_enc_csn_id_coded.nunique()) # lost one patient here\n",
    "has_lv_of_care.pat_enc_csn_id_coded.nunique() # we have at least one per csn \n",
    "\n",
    "# find first event for each csn\n",
    "has_lv_of_care.sort_values(by=['pat_enc_csn_id_coded', 'event_time_jittered_utc',\n",
    "                              'seq_num_in_enc', 'seq_num_in_bed_min'], inplace=True)\n",
    "first_label = has_lv_of_care.groupby(['pat_enc_csn_id_coded']).first().reset_index()\n",
    "\n",
    "sec_since_admit = first_label.effective_time_since_admit.astype('timedelta64[s]')\n",
    "hour_since_admit = sec_since_admit / 3600 # num of sec in an hour\n",
    "print(hour_since_admit.describe())\n",
    "hour_since_admit.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have the first event for each CSN\n",
    "first_label.pat_enc_csn_id_coded.nunique() # 713 - we have everyone, except that one that dropped off\n",
    "first_label_short = first_label[['pat_enc_csn_id_coded', 'pat_lv_of_care', 'effective_time_since_admit']]\n",
    "\n",
    "# check out lv of care here\n",
    "print(first_label_short.pat_lv_of_care.value_counts())\n",
    "\n",
    "# make sure no null values\n",
    "print(sum(first_label_short.pat_lv_of_care.isnull())) # 0 = good\n",
    "\n",
    "# create label\n",
    "first_label_short['first_label'] = (first_label_short.pat_lv_of_care == 'Critical Care').astype(int)\n",
    "\n",
    "print(first_label_short.first_label.value_counts()) # makes sense\n",
    "\n",
    "# rename the time since admit column\n",
    "first_label_short.rename({'effective_time_since_admit': 'first_label_time_since_admit'}, \n",
    "                         axis='columns', inplace=True)\n",
    "\n",
    "first_label_short.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking into the first label time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_short['hours_since_admit'] = first_label_short.first_label_time_since_admit / pd.Timedelta('1 hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_first_labels = first_label_short.sort_values('hours_since_admit', ascending=False)\n",
    "ordered_first_labels.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "csn = ordered_first_labels.pat_enc_csn_id_coded.values[i]\n",
    "joined_cohort_adt[joined_cohort_adt.pat_enc_csn_id_coded == csn][['pat_enc_csn_id_coded', 'admit_time',\n",
    "                                                                 'pat_class', 'pat_lv_of_care',\n",
    "                                                                 'effective_time_jittered_utc', \n",
    "                                                                 'event_time_jittered_utc',\n",
    "                                                                 'effective_time_since_admit']].sort_values('effective_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "csn = ordered_first_labels.pat_enc_csn_id_coded.values[i]\n",
    "switch_cohort_adt[switch_cohort_adt.pat_enc_csn_id_coded == csn][['pat_enc_csn_id_coded', 'admit_time',\n",
    "                                                                 'pat_class', 'pat_lv_of_care',\n",
    "                                                                 'effective_time_jittered_utc', \n",
    "                                                                 'event_time_jittered_utc',\n",
    "                                                                 'effective_time_since_admit']].sort_values('effective_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_label_short.hist('hours_since_admit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the first labels to the new cohort\n",
    "new_cohort_labels = filtered_cohort_labels3.merge(first_label_short[['pat_enc_csn_id_coded', 'first_label', 'first_label_time_since_admit']],\n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cohort_labels_full = new_cohort_labels[~new_cohort_labels.pat_enc_csn_id_coded.isin(no_labels_csns)]\n",
    "\n",
    "print(\"new cohort labels\")\n",
    "describe_df(new_cohort_labels)\n",
    "print(\"\\nnew cohort labels full\")\n",
    "describe_df(new_cohort_labels_full) # we lose those 82 csns that had no labels across the board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at patient trajectories\n",
    "\n",
    "Some people do not go straight from Emergency Services to Inpatient. They go to other places like Observation in between. I don't remember if this was what we wanted to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = filtered_cohort_adt.sort_values(by=['anon_id', 'pat_enc_csn_id_coded', \n",
    "                                            'event_time_jittered_utc', 'seq_num_in_enc', 'seq_num_in_bed_min'])\n",
    "\n",
    "# keep only cases where pat_lv_of_care changed from row above or csn changed\n",
    "# logic: (row.csn == last.csn) --> (row.care != last.care) ::: p --> q\n",
    "# equivalent: (!(row.csn == last.csn) OR (row.care != last.care)) ::: !p OR q\n",
    "df_temp['csn_pat_class'] = df_temp.pat_enc_csn_id_coded.astype(str) + df_temp.pat_class\n",
    "\n",
    "df_temp['match'] = ~(df_temp.csn_pat_class ==  df_temp.csn_pat_class.shift())\n",
    "df_temp\n",
    "\n",
    "df_change = df_temp[~(df_temp.csn_pat_class ==  df_temp.csn_pat_class.shift())]\n",
    "                                      \n",
    "\n",
    "# want to see trajectories for each patient on the adt table\n",
    "grouped = df_change.sort_values(by=['anon_id', 'pat_enc_csn_id_coded', 'effective_time_jittered_utc'])[['pat_enc_csn_id_coded', 'pat_class']]\n",
    "pat_traj = grouped.groupby('pat_enc_csn_id_coded').pat_class.apply(lambda x: ' -> '.join(x)).reset_index()\n",
    "\n",
    "# join to the adt table\n",
    "pat_traj['trajectory'] = pat_traj.pat_class\n",
    "new_adt = filtered_cohort_adt.merge(pat_traj, how='left', on='pat_enc_csn_id_coded')\n",
    "\n",
    "trajectories = new_adt.trajectory.unique()\n",
    "\n",
    "new_adt.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pat_traj.groupby('trajectory').pat_enc_csn_id_coded.count().reset_index()\n",
    "print(counts.sort_values('pat_enc_csn_id_coded', ascending=False).head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(trajectories)):\n",
    "    print(i, \" : \", trajectories[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "traj = trajectories[i]\n",
    "print(traj)\n",
    "traj_csns = new_adt[new_adt.trajectory == traj].pat_enc_csn_id_coded.values\n",
    "\n",
    "k = 0\n",
    "df_temp[df_temp.pat_enc_csn_id_coded == traj_csns[k]].sort_values('effective_time_jittered_utc').drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the switch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_cohort_labels_full.has_admit_label.value_counts())\n",
    "new_cohort_labels_full.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move values from events that have admit labels to first label\n",
    "def first_label(row):\n",
    "    if isinstance(row['admit_label'], int):\n",
    "        return row.admit_label\n",
    "    else:\n",
    "        return row.first_label\n",
    "\n",
    "def first_label_time(row):\n",
    "    if isinstance(row['admit_label'], int):\n",
    "        return 0\n",
    "    else:\n",
    "        return row.first_label_time_since_admit\n",
    "\n",
    "new_cohort_labels_full['first_label_full'] = new_cohort_labels_full.apply(lambda row: \n",
    "                                                                          first_label(row),\n",
    "                                                                         axis=1)\n",
    "new_cohort_labels_full['first_label_time_since_admit_full'] = new_cohort_labels_full.apply(lambda row: \n",
    "                                                                          first_label_time(row),\n",
    "                                                                         axis=1)\n",
    "\n",
    "print(new_cohort_labels_full.first_label_full.value_counts())\n",
    "print(new_cohort_labels_full.first_label.value_counts())\n",
    "print(sum(new_cohort_labels_full.first_label_full.isnull()))\n",
    "\n",
    "new_cohort_labels_full.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "check = new_cohort_labels_full\n",
    "print(sum(check.first_label_full.isnull()))\n",
    "print(sum(check.first_label_time_since_admit_full.isnull()))\n",
    "\n",
    "\n",
    "check = new_cohort_labels_full[new_cohort_labels_full.admit_label.isnull()]\n",
    "\n",
    "print(sum(check.first_label_full.isnull()))\n",
    "print(sum(check.first_label_time_since_admit_full.isnull()))\n",
    "\n",
    "check.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = new_cohort_labels_full[~new_cohort_labels_full.admit_label.isnull()]\n",
    "\n",
    "print(sum(check.first_label_full.isnull()))\n",
    "print(sum(check.first_label_time_since_admit_full.isnull()))\n",
    "\n",
    "check.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create switch labels now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cohort_labels_full.first_label_full = new_cohort_labels_full.first_label_full\n",
    "\n",
    "# acute to critical\n",
    "new_cohort_labels_full['acute_to_critical_label'] = (\n",
    "    (new_cohort_labels_full.first_label_full == 0) &\n",
    "    (new_cohort_labels_full.label_24hr_recent == 1)).astype(int)\n",
    "\n",
    "new_cohort_labels_full.acute_to_critical_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critical to acute\n",
    "new_cohort_labels_full['critical_to_acute_label'] = (\n",
    "    (new_cohort_labels_full.first_label_full == 1) &\n",
    "    (new_cohort_labels_full.label_24hr_recent == 0)).astype(int)\n",
    "\n",
    "new_cohort_labels_full.critical_to_acute_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cohort_labels_full.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = new_cohort_labels_full.copy()\n",
    "\n",
    "# drop unwanted columns\n",
    "final_labels.drop(['first_label', 'first_label_time_since_admit'], axis=1, errors='ignore',\n",
    "                 inplace=True)\n",
    "\n",
    "# rename columns\n",
    "final_labels.rename({'first_label_full': 'first_label',\n",
    "                    'first_label_time_since_admit_full': 'first_label_time_since_admit'},\n",
    "                   inplace=True, axis=1)\n",
    "\n",
    "# final_labels['first_label'] = final_labels.first_label.astype(int)\n",
    "\n",
    "final_labels.drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "final_labels.to_csv(\"{}/triage_cohort_2019_all_labels.csv\".format(datadir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = pd.read_csv(\"{}/triage_cohort_2019_all_labels.csv\".format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for colname in final_labels.columns:\n",
    "    print(final_labels[colname].value_counts())\n",
    "    print(sum(final_labels[colname].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update format of table columns\n",
    "\n",
    "There is a column that is a double, so we will update to keep everything consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = pd.read_csv(\"{}/triage_cohort_2019_all_labels.csv\".format(datadir))\n",
    "final_labels.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the types of each column\n",
    "final_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change any of the float columns to int64\n",
    "float_cols = ['admit_label', 'label_12hr_recent', 'first_label']\n",
    "\n",
    "for col in float_cols:\n",
    "    final_labels[col] = final_labels[col].astype('Int64')\n",
    "\n",
    "final_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final cohort size is 42,475\n",
    "print(sum(final_labels.admit_label.isnull()))\n",
    "print(sum(~final_labels.admit_label.isnull()))\n",
    "\n",
    "final_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "final_labels.to_csv(\"{}/triage_to_keep_cohort_with_labels_updated.csv\".format(datadir), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
