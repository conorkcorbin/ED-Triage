{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deaths Analysis 2019\n",
    "\n",
    "Checking on the patients that died in our cohort. Specifically looking for any that died within 24 hours of being admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in files that were pulled and saved from BQ.\n",
    "\n",
    "`cohorts_2019_deaths.csv` and `cohort_2018_prior_deaths.csv` pull the demographics table for our cohort with the death date included. If the death date is NaN, then the individual is considered alive.\n",
    "\n",
    "The 2018 data was pulled from the initial database, and then 2019 data was pulled from a later release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in files that we need\n",
    "datadir = \"../../../../2019_data/\"  # point to directory with saved data files\n",
    "deaths = pd.read_csv(\"{}cohort_2019_deaths.csv\".format(datadir))\n",
    "deaths18 = pd.read_csv(\"{}cohort_2018_prior_deaths.csv\".format(datadir))\n",
    "cohort = pd.read_csv(\"{}triage_to_keep_cohort_with_labels_updated.csv\".format(datadir))\n",
    "\n",
    "# labels = pd.read_csv(\"{}triage_cohort_2019_all_labels.csv\".format(datadir))\n",
    "# cohort = pd.read_csv(\"{}features_demos_vitals_labs.csv\".format(datadir))\n",
    "\n",
    "# use this to identify test/train set - pulled from Box\n",
    "results = pd.read_csv(\"{}lightgbm_test_results_24hr_max.csv\".format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths18.head()\n",
    "deaths.ANON_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this to print out dataframes with specific columns hidden\n",
    "\n",
    "forrepo = 1 # change this to 0 if you want to see hidden columns displayed\n",
    "\n",
    "hidecols = []\n",
    "if forrepo:\n",
    "    hidecols=['anon_id', 'pat_enc_csn_id_coded', 'inpatient_data_id_coded'] # these are hidden columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique anon_id and csns in our cohort to begin with\n",
    "# 29,891 anon_id\n",
    "# 43,207 csns\n",
    "print(cohort.anon_id.nunique())\n",
    "print(cohort.pat_enc_csn_id_coded.nunique())\n",
    "# cohort.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many anon_ids do we have in the deaths table? 28,985\n",
    "cohort_deaths = deaths[deaths.ANON_ID.isin(cohort.anon_id)]\n",
    "print(cohort_deaths.ANON_ID.nunique())\n",
    "# cohort_deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many anon_id (aka rit_uid) are in the deaths18 table? 26,670\n",
    "cohort_deaths = deaths18[deaths18.rit_uid.isin(cohort.anon_id)]\n",
    "print(cohort_deaths.rit_uid.nunique())\n",
    "# deaths18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the csns that we care about\n",
    "csns = cohort.pat_enc_csn_id_coded.unique()\n",
    "\n",
    "# filter labels down to these csns also\n",
    "labels_2019 = cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2018 prior death dates\n",
    "cohort_deaths18 = deaths18[deaths18.rit_uid.isin(labels_2019.anon_id)]\n",
    "cohort_deaths18.rename({'rit_uid':'anon_id',\n",
    "                       'death_date_jittered':'death_date_2018'},\n",
    "                      inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# get the 2019 deaths\n",
    "cohort_deaths19 = deaths[deaths.ANON_ID.isin(labels_2019.anon_id)]\n",
    "cohort_deaths19.rename({'ANON_ID':'anon_id',\n",
    "                       'DEATH_DATE_JITTERED':'death_date_2019'},\n",
    "                      inplace=True, axis=1)\n",
    "# cohort_deaths19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_deaths18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 2018prior and 2019 death dates\n",
    "all_deaths = cohort_deaths18.merge(cohort_deaths19, how='outer')\n",
    "# all_deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out people who have a death date\n",
    "died = all_deaths[(~all_deaths.death_date_2018.isnull()) | (~all_deaths.death_date_2019.isnull())]\n",
    "# died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the deaths data to labels\n",
    "labels_deaths = labels_2019.merge(all_deaths, how='left')\n",
    "\n",
    "# change the dates to datetime\n",
    "labels_deaths.death_date_2018 = pd.to_datetime(labels_deaths.death_date_2018)\n",
    "labels_deaths.death_date_2019 = pd.to_datetime(labels_deaths.death_date_2019)\n",
    "\n",
    "# get the year from the dates\n",
    "# labels_deaths['death_year_2019'] = pd.DatetimeIndex(labels_deaths['death_date_2019']).year\n",
    "# labels_deaths['death_year_2018'] = pd.DatetimeIndex(labels_deaths['death_date_2018']).year\n",
    "\n",
    "# column indicating whether someone died\n",
    "labels_deaths['died'] = (~labels_deaths.death_date_2018.isnull()) | (~labels_deaths.death_date_2019.isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the 2019 date only if 2018prior is NaN\n",
    "# ie they died during or after 2019\n",
    "\n",
    "# everyone who died in 2020 or 2019 has their death dates in the 2019 deaths data\n",
    "labels_deaths[(labels_deaths.died) & \n",
    "              (labels_deaths.death_date_2018.isnull())].drop(hidecols, axis=1, errors='ignore').head()\n",
    "\n",
    "#              (~labels_deaths.death_year_2019.isin([2019,2020]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the earliest death date - will be from 2018prior if it exists \n",
    "# DON'T DO THIS! -- all dates are rejittered for the 2019 data so it's okay to just use the 2019 death dates\n",
    "# labels_deaths['death_date'] = labels_deaths[['death_date_2019', 'death_date_2018']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_deaths.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of the table with death dates from each database pull\n",
    "to_save = labels_deaths.rename({'death_date_2018':'death_date_starrdatalake2018',\n",
    "                               'death_date_2019':'death_date_shccore'})\n",
    "to_save.to_csv(\"{}labels_deaths_2019_2018_dates.csv\".format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing_death2019 = labels_deaths[(labels_deaths.death_date_2019.isnull()) &\n",
    "#              (~labels_deaths.death_date_2018.isnull())]\n",
    "\n",
    "# missing_death2019[['anon_id', 'admit_date', 'death_date_2018', 'death_date_2019', 'admit_death_delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_deaths['death_date'] = labels_deaths.death_date_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_deaths.drop(['death_date_2018', 'death_date_2019', \n",
    "#                     'match_2018_2019', 'death_year_2019', 'death_year_2018'],\n",
    "#                   axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find out how much time has passed since admit time and death\n",
    "labels_deaths['admit_time'] = pd.to_datetime(labels_deaths.admit_time) \n",
    "labels_deaths['death_date'] = pd.to_datetime(labels_deaths.death_date)\n",
    "\n",
    "# get the date from admit time\n",
    "labels_deaths['admit_date'] = labels_deaths.admit_time.dt.date\n",
    "\n",
    "\n",
    "labels_deaths['admit_date'] = pd.to_datetime(labels_deaths.admit_date)\n",
    "# calculate time between death and admit\n",
    "labels_deaths['admit_death_delta'] = labels_deaths.death_date - labels_deaths.admit_date\n",
    "\n",
    "labels_deaths.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check test cohort\n",
    "\n",
    "Filter down to the test set and check on number of deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to mark whether csn is in test set\n",
    "labels_deaths['in_test_set'] = labels_deaths.pat_enc_csn_id_coded.isin(results.pat_enc_csn_id_coded).astype('int')\n",
    "\n",
    "# test set numbers\n",
    "# csns = 43,207 total\n",
    "# test = 33,111\n",
    "# train = 10,096\n",
    "print(labels_deaths.pat_enc_csn_id_coded.nunique())\n",
    "print(labels_deaths.in_test_set.value_counts())\n",
    "\n",
    "# # save to file\n",
    "labels_deaths.to_csv(\"{}full_cohort_2019_deaths_with_labels.csv\".format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_deaths.drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter down to test set\n",
    "# test_deaths = labels_deaths[labels_deaths.in_test_set]\n",
    "\n",
    "# print(labels_deaths.pat_enc_csn_id_coded.nunique())\n",
    "# print(results.pat_enc_csn_id_coded.nunique())\n",
    "# print(test_deaths.pat_enc_csn_id_coded.nunique())\n",
    "# test_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Died within 1 day\n",
    "\n",
    "Find out which individuals died within 24 hours of being admitted.\n",
    "\n",
    "If an individual was in non-ICU, but died within 24 hours, change their label to 1. Indicate that these individuals were in a critical condition.\n",
    "\n",
    "I will add a column called `died_within_24hrs` which can be used to change the existing label columns downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=1\n",
    "died_1day = labels_deaths[labels_deaths.admit_death_delta <= timedelta(days=days)]\n",
    "\n",
    "labels_deaths['died_within_24hrs'] = (labels_deaths.admit_death_delta <= timedelta(days=days)).astype(int)\n",
    "\n",
    "labels_deaths.sort_values('admit_death_delta').drop(hidecols, axis=1, errors='ignore').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_deaths.died.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one individual with negative delta -- may be an entry error? **\n",
    "# maybe remove this individual later??\n",
    "# everyone else seems fine\n",
    "died_1day.admit_death_delta.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how are these individuals distributed as far as admit label goes?\n",
    "died_1day.admit_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how do the recent 24hr labels look?\n",
    "died_1day.label_24hr_recent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the table with the new labels \n",
    "cleaned_labels = labels_deaths.drop(['death_date_2018', 'death_date_2019'], axis=1, errors='ignore')\n",
    "cleaned_labels.died = cleaned_labels.died.astype(int)\n",
    "cleaned_labels.drop(hidecols, axis=1, errors='ignore').head()\n",
    "\n",
    "cleaned_labels.to_csv(\"{}labels_with_death_delta.csv\".format(datadir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_labels.pat_enc_csn_id_coded.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- Below this point is for plotting only ---\n",
    "\n",
    "Will remove this and move to another file later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remake plot for admissions to ICU at each hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to describe the tables\n",
    "def describe_df(df):\n",
    "    print(\"df shape\", df.shape)\n",
    "    print(\"unique CSNs: \", df.pat_enc_csn_id_coded.nunique())\n",
    "    print(\"unique patients: \", df.anon_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the adt file\n",
    "adt_file = \"{}triage_cohort_adt_2019.csv\".format(datadir)\n",
    "adt = pd.read_csv(adt_file)\n",
    "describe_df(adt)\n",
    "adt.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_adt = adt[adt.pat_enc_csn_id_coded.isin(cohort.pat_enc_csn_id_coded)]\n",
    "describe_df(cohort_adt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change time columns to datetime\n",
    "cohort_adt.effective_time_jittered_utc = pd.to_datetime(cohort_adt.effective_time_jittered_utc).dt.tz_localize(None)\n",
    "cohort.admit_time = pd.to_datetime(cohort.admit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_cohort_adt = cohort.merge(cohort_adt, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut down on space\n",
    "cols = ['anon_id', 'pat_enc_csn_id_coded', 'label_24hr_recent', \n",
    "       'admit_time', 'pat_class', 'pat_lv_of_care', 'pat_service',\n",
    "       'effective_time_jittered_utc', 'seq_num_in_enc']\n",
    "joined_cohort_adt_less = joined_cohort_adt[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_cohort_adt_less.shape)\n",
    "print(cohort_adt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the adt table in case we crash again\n",
    "joined_cohort_adt_less.to_csv(\"{}joined_cohort_adt_2019.csv\".format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_cohort_adt_less.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the adt table by seqnum in encounter\n",
    "joined_cohort_adt_less.sort_values(['pat_enc_csn_id_coded', 'seq_num_in_enc'], inplace=True)\n",
    "joined_cohort_adt_less.head().drop(hidecols, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the time since event\n",
    "joined_cohort_adt_less['time_since_admit'] = joined_cohort_adt_less.apply(\n",
    "    lambda x: x.effective_time_jittered_utc - x.admit_time, axis=1)\n",
    "joined_cohort_adt_less.head()\n",
    "\n",
    "joined_cohort_adt_less.sort_values(['pat_enc_csn_id_coded', 'seq_num_in_enc'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get labels\n",
    "def get_labels(window_hours):\n",
    "    df_lofc = joined_cohort_adt_less\n",
    "\n",
    "    # Filter df_lofc so that we only look window_hours hours into admission\n",
    "    df_lofc = df_lofc[(df_lofc['time_since_admit'] < timedelta(hours=window_hours))\n",
    "                      & (df_lofc.time_since_admit \n",
    "                                       >= timedelta(hours=0))]\n",
    "\n",
    "    def was_placed_in_critical_care(arr):\n",
    "        \"\"\"Returns true if patient placed in crtical care within 24 hours of admit\n",
    "           Assumes we have already done the 24 hours logic\n",
    "           Assumes no overlapping csn ids... \"\"\"\n",
    "        for a in arr:\n",
    "            if a == 'Critical Care':\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    label_name = \"label_{}hr\".format(window_hours)\n",
    "    \n",
    "    df_labels = df_lofc.groupby('pat_enc_csn_id_coded').agg({\n",
    "        'anon_id' : 'first',\n",
    "        'admit_time' : 'first',\n",
    "        'pat_lv_of_care' : was_placed_in_critical_care}).rename(\n",
    "        columns={\"pat_lv_of_care\" : label_name}).reset_index()[['anon_id', 'pat_enc_csn_id_coded', \n",
    "                                                                'admit_time', label_name]]\n",
    "    df_labels.head()\n",
    "\n",
    "    print(df_labels.groupby(label_name).count())\n",
    "    \n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_24hr = get_labels(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_24hr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_24hr.rename({'label_24hr':'label_24hr00'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_df(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_labels = labels[labels.pat_enc_csn_id_coded.isin(cohort.pat_enc_csn_id_coded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabs = cohort_labels.merge(labels_24hr[['anon_id', 'pat_enc_csn_id_coded', 'label_24hr00']], how='left')\n",
    "newlabs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabs[newlabs.label_max24 != newlabs.label_24hr00]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "names = [x for x in range(48)]\n",
    "plt.figure(figsize=(15,8))\n",
    "# Create green Bars\n",
    "barlist = plt.bar(names, pos_count, color='slateblue', edgecolor='white')\n",
    "barlist[24].set_color('r')\n",
    "\n",
    "# Custom x axis\n",
    "\n",
    "plt.xticks(names)\n",
    "plt.xlabel(\"Hours since admit\")\n",
    "plt.ylabel(\"Positive cases\")\n",
    "plt.title(\"Positive labels X hours after admission\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot\n",
    "names = [x for x in range(48)]\n",
    "plt.figure(figsize=(15,8))\n",
    "# Create green Bars\n",
    "barlist = plt.plot(names, pos_count, color='cornflowerblue')\n",
    "\n",
    "# Custom x axis\n",
    "\n",
    "plt.xticks(names)\n",
    "plt.xlabel(\"Hours since admit\")\n",
    "plt.ylabel(\"Positive cases\")\n",
    "plt.title(\"Positive labels X hours after admission\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "names = [x for x in range(1,48)]\n",
    "plt.figure(figsize=(15,8))\n",
    "# Create green Bars\n",
    "barlist = plt.plot(names, pos_count[1:], color='cornflowerblue')\n",
    "\n",
    "# Custom x axis\n",
    "\n",
    "plt.xticks(names)\n",
    "plt.xlabel(\"Hours since admit\")\n",
    "plt.ylabel(\"Positive cases\")\n",
    "plt.title(\"Positive labels X hours after admission\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc24 = pos_perc[24]\n",
    "perc24\n",
    "\n",
    "diffs = pos_perc - perc24\n",
    "diffs\n",
    "\n",
    "# plot\n",
    "names = [x for x in range(48)]\n",
    "plt.figure(figsize=(15,8))\n",
    "# Create green Bars\n",
    "barlist = plt.bar(names, diffs, color='dodgerblue', edgecolor='white')\n",
    "# barlist[24].set_color('crimson')\n",
    "\n",
    "# Custom x axis\n",
    "\n",
    "plt.xticks(names)\n",
    "plt.xlabel(\"Hours since admit\")\n",
    "plt.ylabel(\"Percent positive cases at 24hrs - Percent positive cases at X hours\")\n",
    "plt.title(\"Difference in percentage of positive labels at X hours after admission vs 24 hours after admission\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plot\n",
    "names = [x for x in range(1,48)]\n",
    "plt.figure(figsize=(15,8))\n",
    "# Create green Bars\n",
    "barlist = plt.bar(names, diffs[1:], color='dodgerblue', edgecolor='white')\n",
    "# barlist[24].set_color('crimson')\n",
    "\n",
    "# Custom x axis\n",
    "\n",
    "plt.xticks(names)\n",
    "plt.xlabel(\"Hours since admit\")\n",
    "plt.ylabel(\"Percent positive cases at 24hrs - Percent positive cases at X hours\")\n",
    "plt.title(\"Difference in percentage of positive labels at X hours after admission vs 24 hours after admission\")\n",
    " \n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admits only during that hour\n",
    "\n",
    "Look at admits only at that hour to separate the cumulative effect that's going on with the earlier graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels[\"admit_at_{}hr\".format(0)] = all_labels[\"label_0hr\"]\n",
    "for i in range(1,48):\n",
    "        key = \"admit_at_{}hr\".format(i)\n",
    "        all_labels[key] = all_labels[\"label_{}hr\".format(i)] & ~all_labels[\"label_{}hr\".format(i-1)]\n",
    "\n",
    "cols = [x for x in all_labels.columns if \"admit_at\" in x]\n",
    "all_labels[cols]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
